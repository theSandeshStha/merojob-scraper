{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35679ca3-1fb6-454d-913d-4f891dff5d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing job 196 of 196\n",
      "CSV file \"job_informations.csv\" has been successfully updated.\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "import re\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def fetch_job_data(url):\n",
    "    res = requests.get(url)\n",
    "    soup = BeautifulSoup(res.content, 'html.parser')\n",
    "    job_data = []\n",
    "\n",
    "    job_cards = soup.find_all('div', class_='col-md-4 border-right border-bottom job-card')\n",
    "    for job_card in job_cards:\n",
    "        organization_name_meta = job_card.find('meta', itemprop='name')\n",
    "        organization_name = organization_name_meta['content'] if organization_name_meta else ''\n",
    "        organization_href_tag = job_card.find('a', class_='h6 mb-1')\n",
    "        organization_href = \"https://www.merojob.com\" + organization_href_tag['href'] if organization_href_tag else ''\n",
    "        \n",
    "        position_tags = job_card.find_all('a', class_='job_title hover-primary')\n",
    "        for position_tag in position_tags:\n",
    "            job_position = position_tag.get('title', '')  \n",
    "            match = re.search(r'(.+?) - Apply Before', job_position)\n",
    "            job_title = match.group(1).strip() if match else job_position\n",
    "            job_position_href = \"https://www.merojob.com\" + position_tag.get('href', '')  \n",
    "            job_data.append([organization_name, organization_href, job_title, job_position_href])\n",
    "    \n",
    "    return job_data\n",
    "\n",
    "def save_job_data_to_csv(job_data, filename):\n",
    "    with open(filename, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Organization Name', 'Organization Link', 'Job Position', 'Position Link'])\n",
    "        writer.writerows(job_data)\n",
    "    print(f'CSV file \"{filename}\" has been successfully created.')\n",
    "\n",
    "def extract_job_info(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to retrieve the webpage. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    job_info = {}\n",
    "\n",
    "    job_info['Job Title'] = soup.find('h1', itemprop='title').text if soup.find('h1', itemprop='title') else 'N/A'\n",
    "    job_info['Deadline Date'] = soup.find('meta', itemprop='validThrough')['content'] if soup.find('meta', itemprop='validThrough') else 'N/A'\n",
    "    \n",
    "    basic_info_table = soup.find('div', class_='card-group').find('div', class_='card-body').find('table')\n",
    "    if basic_info_table:\n",
    "        for row in basic_info_table.find_all('tr'):\n",
    "            key = row.find_all('td')[0].get_text()\n",
    "            value = row.find_all('td')[2].get_text().strip()\n",
    "            job_info[key] = value\n",
    "    \n",
    "    job_specification = soup.find('h3', string='Job Specification')\n",
    "    if job_specification:\n",
    "        job_specification_table = job_specification.find_next('table')\n",
    "        job_info['Education Level'] = job_specification_table.find('span', itemprop='educationRequirements').text if job_specification_table.find('span', itemprop='educationRequirements') else 'N/A'\n",
    "        job_info['Experience Required'] = job_specification_table.find('span', itemprop='experienceRequirements').text if job_specification_table.find('span', itemprop='experienceRequirements') else 'Not specified'\n",
    "        \n",
    "        skills_span = job_specification_table.find('span', itemprop='skills')\n",
    "        if skills_span:\n",
    "            job_info['Professional Skills'] = ', '.join(tag.text.strip() for tag in skills_span.find_all('span', class_='badge badge-light border rounded p-1'))\n",
    "        else:\n",
    "            job_info['Professional Skills'] = 'N/A'\n",
    "    \n",
    "    qualifications_experience_tag = soup.find('strong', string='Qualification & Experience:')\n",
    "    if qualifications_experience_tag:\n",
    "        job_info['Qualifications and Experience'] = '\\n'.join([item.text for item in qualifications_experience_tag.find_next('ul').find_all('li')])\n",
    "    \n",
    "    skills_tag = soup.find('strong', string='Skills:')\n",
    "    if skills_tag:\n",
    "        job_info['Skills'] = '\\n'.join([item.text for item in skills_tag.find_next('ul').find_all('li')])\n",
    "    \n",
    "    description = soup.find('h3', string='Job Description')\n",
    "    if description:\n",
    "        job_description = description.find_next('ul').find_all('li')\n",
    "        job_info['Job Description'] = '\\n'.join([item.text for item in job_description])\n",
    "    \n",
    "    return job_info\n",
    "\n",
    "def save_job_infos_to_csv(job_infos, filename):\n",
    "    if not job_infos:\n",
    "        print(\"No job information to save.\")\n",
    "        return\n",
    "\n",
    "    file_exists = os.path.isfile(filename) and os.path.getsize(filename) > 0\n",
    "    with open(filename, 'a', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        if not file_exists:\n",
    "            headers = job_infos[0].keys()\n",
    "            writer.writerow(headers)\n",
    "        for job_info in job_infos:\n",
    "            writer.writerow(job_info.values())\n",
    "    \n",
    "    print(f'CSV file \"{filename}\" has been successfully updated.')\n",
    "\n",
    "def main():\n",
    "    base_url = \"https://www.merojob.com/\"\n",
    "    job_links_csv = \"links_to_jobs.csv\"\n",
    "    job_infos_csv = \"job_informations.csv\"\n",
    "\n",
    "    job_data = fetch_job_data(base_url)\n",
    "    save_job_data_to_csv(job_data, job_links_csv)\n",
    "\n",
    "    df = pd.read_csv(job_links_csv)\n",
    "    job_infos = []\n",
    "    for idx, row in df.iterrows():\n",
    "        clear_output(wait=True)\n",
    "        print(f\"Processing job {idx + 1} of {len(df)}\")\n",
    "        job_info = extract_job_info(row['Position Link'])\n",
    "        if job_info:\n",
    "            job_infos.append(job_info)\n",
    "    \n",
    "    save_job_infos_to_csv(job_infos, job_infos_csv)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
